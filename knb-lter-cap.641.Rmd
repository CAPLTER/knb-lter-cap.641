---
title: "knb-lter-cap.641"
output: html_document
editor_options: 
  chunk_output_type: console
---

FOR SRBP: there are six birding points at each site, two birding points along
each of the three transects, yielding, for example, Tonto_mid_B1, Tonto_mid_B2
(recall that there are three herp plots along each transect). To this point, a
single birder (formerly Melanie), birded at all six points four times per
year. The other two birders, birded at a single core site during the two
regular birding seasons.

```{r libraries}
library(EML)
library(tidyverse)
library(tools)
library(aws.s3)
library(capeml)
library(gioseml)
```

_2020-08-20_ For knb-lter-cap.641.4, observation data were filtered to include
up to only spring 2019 (2019-05-03) as data were QC'd to that point only.

_2016-12-02_ The meaning of 'flying' in the birds table is unclear. There are
1962 records where flying = 1. All of these except for two records have
distance = FT. However, not all records where distance = FT have a distance = 1
(any any value for that matter). Adding confusion, in her metadata, Corinna has
listed that flying = NULL is true, but then what would be the meaning of flying
= 0, and that would mean that most birds were flying. I am not certain, but my
impression is that flying was a precursor to FT. A "flying" option is not on
the current datasheet, nor on an earlier one revised in 2004. I am going to
omit flying from the publication of these data as I think it is more confusing
than helpful (and I cannot explain its meaning).

# srbp_birds

```{r srbp_birds}

# note that this select statement does not include wind speed, wind dir, air
# temp, or cloud cover as those variables have not been collected for a long
# time and are not relevant to the more recent SRBP observations

srbp_birds <- dbGetQuery(mysql_prod, "
SELECT
  sites.site_code,
  surveys.survey_date,
  surveys.time_start,
  surveys.time_end,
  surveys.observer,
  surveys.notes AS survey_notes,
  surveys.human_activity_notes,
  surveys.wind,
  surveys.precipitation,
  surveys.disturbances,
  surveys.sight_obstruct,
  surveys.noise_level,
  surveys.site_condition,
  surveys.non_bird_species,
  bird_taxons.code,
  bird_taxons.common_name,
  birds.distance,
  birds.bird_count,
  birds.notes AS observation_notes,
  birds.seen,
  birds.heard,
  birds.direction,
  birds.QCcomment
FROM lter34birds.surveys
JOIN lter34birds.sites ON (surveys.site_id = sites.site_id)
JOIN lter34birds.birds ON (surveys.survey_id = birds.survey_id)
JOIN lter34birds.bird_taxons ON (birds.bird_taxon_id = bird_taxons.id)
WHERE
  sites.sample LIKE 'SRBP'
ORDER BY survey_date;")

srbp_birds[srbp_birds == ""] <- NA # lots of missing values, convert to NA

# pulling this code out separately owing to its verbosity for a singular
# purpose: getting the intials of the observers and presenting those instead of
# the full name

srbp_birds <- srbp_birds %>%
  mutate(observer = toupper(observer)) %>%
  separate(observer, c("name1", "name2"), " ", remove = T) %>%
  mutate(
    init1 = str_extract(name1, "\\b\\w"),
    init2 = str_extract(name2, "\\b\\w")
    ) %>%
  unite(observer_initials, init1, init2, sep = "", remove = T)

srbp_birds <- srbp_birds %>%
  mutate(
    reach = str_extract(site_code, "^[^_]+"),
    reach = as.factor(reach),
    survey_date = as.Date(survey_date),
    wind = as.factor(wind),
    precipitation = as.factor(precipitation),
    disturbances = as.factor(disturbances),
    noise_level = as.factor(noise_level),
    distance = as.factor(distance),
    seen = as.factor(seen),
    heard = as.factor(heard),
    direction = as.factor(direction)
    ) %>%
select(
  site_code,
  reach,
  survey_date:time_end,
  observer_initials,
  survey_notes:QCcomment
)

# write_attributes(srbp_birds)
# write_factors(srbp_birds)

srbp_birds_desc <- "bird survey sampling details (site, reach, date, time, observer, site conditions, and notes) and birds surveyed (type, number, distance from observer, behavior)"

srbp_birds_DT <- create_dataTable(
  dfname = srbp_birds,
  description = srbp_birds_desc,
  dateRangeField = "survey_date"
)

```

# additonal_bird_species

```{r additonal-bird-species, eval=TRUE}

additonal_bird_species <- dbGetQuery(mysql_prod, "
SELECT
  sites.site_code,
  surveys.survey_date,
  surveys.time_start,
  surveys.time_end,
  surveys.observer,
  bird_taxons.code,
  bird_taxons.common_name
FROM lter34birds.surveys
JOIN lter34birds.sites ON (surveys.site_id = sites.site_id)
JOIN lter34birds.addl_bird_species ON (surveys.survey_id = addl_bird_species.survey_id)
JOIN lter34birds.bird_taxons ON (addl_bird_species.bird_taxon_id = bird_taxons.id)
WHERE
  sites.sample LIKE 'SRBP'
ORDER BY survey_date;")

additonal_bird_species[additonal_bird_species == ""] <- NA # lots of missing values, convert to NA

additonal_bird_species <- additonal_bird_species %>%
  mutate(observer = toupper(observer)) %>%
  separate(observer, c("name1", "name2"), " ", remove = T) %>%
  mutate(
    init1 = str_extract(name1, "\\b\\w"),
    init2 = str_extract(name2, "\\b\\w")
    ) %>%
  unite(observer_initials, init1, init2, sep = "", remove = T)

additonal_bird_species <- additonal_bird_species %>%
  mutate(
    reach = str_extract(site_code, "^[^_]+"),
    reach = as.factor(reach),
    survey_date = as.Date(survey_date)
    ) %>%
select(
  site_code,
  reach,
  survey_date,
  time_start,
  time_end,
  observer_initials,
  code,
  common_name
)

# write_attributes(additonal_bird_species)
# write_factors(additonal_bird_species)

additonal_bird_species_desc <- "additional bird species seen using the habitat but not recorded during the count"

additonal_bird_species_DT <- create_dataTable(
  dfname = additonal_bird_species,
  description = additonal_bird_species_desc
)

```


There is not enough detail concerning the SRBP sites in the lter34.sites table
to warrant pulling that information. However, SRBP reach characteristics are
relevant so we will publish those details

# reach_characteristics

```{r reach_characteristics}

srbp_reach_characteristics <- dbGetQuery(mysql_prod, "
SELECT
  s.site_code
FROM lter34birds.sites s
WHERE
  s.sample LIKE 'SRBP'
ORDER BY site_code;") %>%
  mutate(reach = str_extract(site_code, "^[^_]+")) %>%
  select(site_code, reach)

herps_reach_chars <- dbGetQuery(pg_prod, "
SELECT
  reach,
  urbanized,
  restored,
  water
FROM herpetofauna.river_reaches;")

srbp_reach_characteristics <- inner_join(srbp_reach_characteristics, herps_reach_chars, by = c("reach")) %>%
  mutate(
    reach = as.factor(reach),
    urbanized = as.factor(urbanized),
    restored = as.factor(restored),
    water = as.factor(water)
  )

srbp_reach_characteristics_desc <- "Salt River reach location of each sampling site, and general characteristics of that portion of the river where sampling is conducted"

# write_attributes(srbp_reach_characteristics)
# write_factors(srbp_reach_characteristics)

srbp_reach_characteristics_DT <- create_dataTable(
  dfname = srbp_reach_characteristics,
  description = srbp_reach_characteristics_desc
)

```

# srbp_bird_locations 

Get the bird survey locations. Here we are extracting these data from the
database as opposed to using an existing shapefile as I am presenting only the
most up-to-date location information (as opposed to the locations and their
changes through time). Double-check the query, it worked with the small number
of SRBP sites with updated locations at the time these were pulled but not sure
its accuracy when the data are more complicated (e.g., a given location having
moved multiple times) and note that I am using only year to reflect the most
recent location, if a site moved twice in a year, month would have to be
considered as well. Also note that I had to include blh.end_date_year in the
query to be able to include it in the HAVING clause.

As with the herp plots, I am struggling as to whether it is appropriate to even
make the exact points public information from a disturbance standpoint, but
also a too-much-knowledge about the organisms standpoint. Finally, now that we
are tracking the movement of plots through time, that would have to be
encapsulated in this publication so as not to confuse a researcher thinking
that all data necessarily come from the same location. Taken together, I think
the better approach is to make a polygon that encapsulates all points (curent
and historical) at each reach. This provides a user with a reasonable
understanding of the location, but obscures (slightly, anyway) the exact
position details.

see core birds for the query if you want only the current sites

```{r spatial_data}

library(capemlGIS)
library(sf)

srbp_bird_locations <- dbGetQuery(mysql_prod, "
  SELECT
  s.site_code,
  blh.lat,
  blh.`long`
  FROM lter34birds.birds_location_histories blh
  JOIN lter34birds.sites s ON (s.site_id = blh.site_id)
  WHERE
  s.sample LIKE 'SRBP'
  ORDER BY site_code;") %>%
  mutate(reach = str_extract(site_code, "^[^_]+")) %>%
  dplyr::select(
    Name = reach,
    lat,
    long
  )

  srbp_bird_locations <- st_as_sf(
    x = srbp_bird_locations,
    coords = c("long", "lat"),
    crs = 4326
    ) %>%
  group_by(Name) %>%
  summarise() %>%
  st_convex_hull()

# write_attributes(srbp_bird_locations)

srbp_bird_locations_desc <- "bird survey locations at select locations along the Salt River in the greater Phoenix metropolitan area; polygons reflect the combined area of all bird survey locations (current and historic) at each river reach"

srbp_bird_locations_SV <- create_spatialVector(
  svname = srbp_bird_locations,
  description = srbp_bird_locations_desc
)

```

# people

```{r people}

# creators

# heather <- addCreator('h', 'bateman')
# paige <- addCreator('paig', 'warren')
# danChilders <- addCreator('d', 'childers')

heather <- create_role(
  firstName = "heather",
  lastName = "bateman",
  roleType = "creator"
)
paige <- create_role(
  firstName = "paige",
  lastName = "warren",
  roleType = "creator"
)

creators <- list(heather, paige)

# metadata providers

stevan <- create_role(
  firstName = "stevan",
  lastName = "earl",
  roleType = "meta"
)
sally <- create_role(
  firstName = "sally",
  lastName = "wittlinger",
  roleType = "meta"
)

metadataProvider <- list(sally, stevan)

```

# coverages

```{r coverages}

begindate <- as.character(min(srbp_birds$survey_date))
enddate <- as.character(max(srbp_birds$survey_date))
geographicDescription <- "CAP LTER study area"
coverage <- set_coverage(
  begin = begindate,
  end = enddate,
  geographicDescription = geographicDescription,
  west = -112.305, east = -111.609,
  north = +33.56, south = +33.3825
)

```

## taxonomic coverage

Taxonomic coverage(s) are constructed using EDI's taxonomyCleanr tool suite.

*Note* that the `taxa_map.csv` built with the `create_taxa_map()` function and
resolving taxonomic IDs (i.e., `resolve_comm_taxa()`) only needs to be run once,
a potentially long process, per version/session -- the taxonomicCoverage can be
built as many times as needed with `resolve_comm_taxa()` once the `taxa_map.csv`
has been generated and the taxonomic IDs resolved.

```{r taxonomyCleanr, eval=FALSE}

library(taxonomyCleanr)

my_path <- getwd() # taxonomyCleanr requires a path (to build the taxa_map)

# Example: draw taxonomic information from existing resource:

# plant taxa listed in the om_transpiration_factors file
birdTaxa <- srbp_birds %>%
  distinct(common_name) %>%
  tibble()

# create or update map. A taxa_map.csv is the heart of taxonomyCleanr. This
# function will build the taxa_map.csv and put it in the path identified with
# my_path.
create_taxa_map(path = my_path, x = birdTaxa, col = "common_name")

# Resolve taxa by attempting to match the taxon name (data.source 3 is ITIS but
# other sources are accessible). Use `resolve_comm_taxa` instead of
# `resolve_sci_taxa` if taxa names are common names but note that ITIS
# (data.source 3) is the only authority taxonomyCleanr will allow for common
# names.
resolve_comm_taxa(path = my_path, data.sources = 3) # in this case, 3 is ITIS

# build the EML taxonomomic coverage
taxaCoverage <- make_taxonomicCoverage(path = my_path)

# add taxonomic to the other coverages
coverage$taxonomicCoverage <- taxaCoverage
```

# dataset

Optionally, provide: scope, abstract, methods, keywords, publication date.
Projects scopes include lter (default), urex, ltreb, and som.

```{r construct-dataset}

dataset <- create_dataset()
```

# add dataTable

```{r dataSet$dataTable}

# add dataTables if relevant

print(ls(pattern = "_DT"))

if (length(ls(pattern = "_DT")) > 0) {

  listOfDataTables <- lapply(ls(pattern = "_DT"), function(DT) { get(DT) } )

  dataset$dataTable  <- listOfDataTables

}

# or add manually
# dataset$dataTable <- list(dataTableOne, dataTableTwo)

```

# add spatialVector

```{r dataSet$spatialVector}

# add spatial vectors if relevant

print(ls(pattern = "_SV"))

if (length(ls(pattern = "_SV")) > 0) {

  listOfSpatialVectors <- lapply(ls(pattern = "_SV"), function(SV) { get(SV) } )

  dataset$spatialVector  <- listOfSpatialVectors

}

# or add manually
# dataset$spatialVector <- list(spatialVectorOne, spatialVectorTwo)

```

# eml

```{r construct_eml, eval=TRUE}

eml <- create_eml()
```

```{r validate_eml, eval=TRUE}

eml_validate(eml)
```

```{r eml_to_file, eval=TRUE}

# write the eml to file
write_cap_eml()
```

# file placement

```{r package-details, eval=TRUE}

# retrieve package details from config.yaml
if (!file.exists("config.yaml")) {
  stop("config.yaml not found")
}
packageIdent <- yaml::yaml.load_file("config.yaml")$packageIdent
packageNum <- yaml::yaml.load_file("config.yaml")$packageNum
```

```{r preview_data_file_to_upload}

# preview data set files that will be uploaded to S3
list.files(pattern = paste0(packageNum, "_"))
```

Move data and final xml files to respective ASU locations.

```{r S3_helper_functions}
# functions and setting for uploading to S3
library(aws.s3)
source("~/Documents/localSettings/aws.s3")
```

```{r upload_data_S3}

# upload files to S3
lapply(list.files(pattern = paste0(packageNum, "_")), data_to_amz)
```

```{r clean_up}

# remove data files
dataFilesToRemove <- dir(pattern = paste0(packageNum, "_"))
file.remove(dataFilesToRemove)

# EML to S3
if(length(list.files(pattern = "*.xml")) == 1) {
  eml_to_amz(list.files(pattern = "*.xml")) } else {
    print("more than one xml file found")
  }

# EML to cap-data-eml and remove file from project
tryCatch({
  
  if(length(list.files(pattern = "*.xml")) == 1) {
    file.copy(list.files(pattern = "*.xml"), "/home/srearl/localRepos/cap-metadata/cap-data-eml/")
    file.remove(list.files(pattern = "*.xml")) } else {
      print("more than one xml file found")
    }
},
warning = function(warn) {
  print(paste("WARNING: ", warn))
},
error = function(err) {
  print(paste("ERROR: ", err))
  
}) # close try catch
```
